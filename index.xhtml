<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8" />
<title>How a Penguin Will Find the God Particle</title>
<link rel="stylesheet" type="text/css" href="../latin/css/latin.css" />
<link rel="stylesheet" type="text/css" href="../sideshow/css/sideshow.css" />
<!--[if IE]>
<script src="../sideshow/js/html5.js"></script>
<![endif]-->
</head>
<body>

<article>

<section class="center">
<header>
<h1>Linux and the LHC</h1>
</header>

<ul class="meta">
<li>Will Maier</li>
<li><a href="http://will.m.aier.us/linux-lhc">http://will.m.aier.us/linux-lhc</a></li>
<li><a href="http://milwaukeelug.org/">Milwaukee Linux Users Group</a></li>
<li>2011.02.12</li>
</ul>

</section>

<section>
<header>
<h1>We use Linux to solve big physics problems</h1>
</header>

<ul>
<li>University of Wisconsin contributes to LHC, CMS collaboration</li>
<li>Goals: find Higgs boson, learn about supersymmetry, new particles?</li>
<li>At LHC: collide particles, generate data</li>
<li>At Fermilab, other national labs: store data</li>
<li>At Wisconsin, other universities: store and analyze data</li>
<li>Big physics problems quickly become huge computing problems</li>
</ul>
</section>

<section>
<header>
<h1>What's a Higgs boson and Why Should We Care?</h1>
</header>

<!-- higgs simulation photo -->

<ul>
<li>Higgs Boson: subatomic particle</li>
<li>Proposed in 1964 by Peter Higgs, not yet observed in experiments</li>
<li>Fundamental particle expected by the theories we use to understand particle physics</li>
<li>We've seen pretty much everything else</li>
<li>To observe the Higgs, need lots and lots of energy</li>
</ul>

</section>

<section>
<header>
<h1>Finding the Higgs</h1>
</header>

<!-- FNAL, CERN photos -->
<!-- bubble chamber photo -->

<ul>
<li>To find a subatomic particle:</li>
<ul>
<li>Smash other particles together at high energy</li>
<li>Record as much data as you can</li>
<li>Throw out as much data as you can</li>
<li>Analyze the data as quickly as you can</li>
</ul>

<li>Accelerators speed up trains of particles, forming beams</li>
<li>Tevatron: proton/antiproton accelerator at Fermilab, near Chicago</li>
<li>LHC: proton accelerator at CERN, near Geneva, Switzerland</li>
</ul>

</section>

<section>
<header>
<h1>From accelerator to detector</h1>
</header>

<!-- http://en.wikipedia.org/wiki/File:CMS_Slice.gif -->

<ul>
<li>Collisions in accelerator observed by detectors</li>
<li>At LHC, two main detector collaborations: CMS, ATLAS</li>
<li>Compete, verify each other's findings</li>
<li>Detectors are like big cameras</li>

<ul>
<li>Millions of silicon and optical sensors wrapped around the accelerator tube</li>
<li>Gather evidence (particle tracks, energy) to identify what was produced in collision</li>
</ul>

</ul>

</section>

<section>
<header>
<h1>Sorting the unknown from the boring</h1>
</header>

<ul>
<li>Most of what is produced in a collision is well-understood (ie. boring)</li>
<li>Each event generates 1 MB of data; crossings happen 40,000,000 times a second</li>
<li>Can't store or process all of that data, so we throw most of it out</li>

<li>Fast hardware triggers</li>
<ul>
<li>Custom FPGAs (designed and built at Wisconsin for CMS)</li>
<li>Discard 999 of every 1000 events</li>
<li>Send 50,000 events per second by fiber to software triggers</li>
</ul>

<li>High Level trigger</li>
<ul>
<li>Software selectors (some also built at Wisconsin)</li>
<li>Run on a Linux cluster</li>
<li>Reduce data again by 1000x, archive 100 events per second to tape</li>
<li>About 50ms to make each selection</li>
</ul>

</ul>

<!--
    "event filter farm"
    http://arxiv.org/abs/hep-ex/0512077
    http://www.slidefinder.net/t/the_european_data_grid_project/6411984
-->

</section>

<section>
<header>
<h1>Now we have tons of data â€”  what next?</h1>
</header>

<ul>
<li>CERN stores a copy of all data to tape</li>
<li>Data moves from CERN to network of national labs, stored on tape again</li>
<li>Universities request datasets and begin analysis</li>
</ul>

</section>

<section>
<header>
<h1>LHC computing infrastructure at Wisconsin</h1>
</header>

<ul>
<li>NNN dedicated machines across three sever rooms</li>
<li>Burst up to NNN machines (GLOW campus grid)</li>
<li>NNN TB of dedicated storage: NNN disks, NNN servers</li>
<li>NNN switches, NNN Gbps uplink</li>
<li>3 people: development (grid/batch), operations (storage), production</li>
<li>Open source software stack built on Linux</li>
</ul>
</section>

<section>
<header>
<h1>Computing environment</h1>
</header>
<ul>
<li>Kickstart/Yum/Cfengine</li>
<li>Python, Shell, Perl, Java</li>
<li>Nagios, cron, tsar, central monitoring</li>
<li>AFS, sendmail, named, httpd</li>
</ul>
</section>

<section>
<header>
<h1>Batch computing</h1>
</header>

<ul>
<li>Condor: batch system for high-througput computing, developed at Wisconsin</li>
<li>Jobs submitted by hundreds of users from around the world; Condor matches tasks to CPU cores</li>
<li>Transparently schedule jobs to "scavenge" idle time on campus computer labs, other clusters</li>
<li>NNN jobs/day, NNN CPU hours/day</li>
<li>From 4 to 24 cores, NNN GB RAM</li>
<li>Kernel optimizations? XXX</li>
</ul>

</section>

<section>
<header>
<h1>Storage</h1>
</header>

<ul>
<li>dCache: distributed file system (Java)</li>
<li>Stores data per file (not block), custom Python software to replicate</li>
<li>Commodity servers with directly attached disks (1U, 2 to 4 SATA, .5 to 2 TB)</li>
<li>Some servers with dedicated RAID (4U, 24 - 32 SATA, 1 - 2 TB)</li>
<li>Namespace lookups are expensive</li>
</ul>

</section>

<section>
<header>
<h1>Current challenges</h1>
</header>

<ul>
<li>Scale computing and storage every year</li>
<li>Speed up data access</li>
<li>Reduce cost of colocated storage/computing</li>
<li>Harden and optimize database services</li>
<li>Simplify architecture</li>
<li>In-depth monitoring, history</li>
<li>Test-driven operations/deployment</li>
<li>Find a way to grow past heat limits</li>
</ul>

</section>

<section>
<header>
<h1>Plans</h1>
</header>

<ul>
<li>s/dCache/HDFS/</li>
<li>Zero-knowledge data access: CMS xrootd redirector</li>
<li>Abstract job submission: GlideinWMS</li>
</ul>

</section>

<section>
<header>
<h1>Get involved</h1>
</header>

<ul>
<li>Learn more about the LHC, CMS, OSG</li>
<li>Participate (Einstein@HOME)</li>
<li>Come to the University of Wisconsin</li>
<li>Find a job</li>
</ul>

</section>

<section>
<header>
<h1></h1>
</header>
<ul>
<li></li>
</ul>
</section>

<!--

flow
    context/background/physics motivation ~ 10m
    wisconsin's role ~ 20m
    future/predictions ~ 10m

quotes
    tux is going to find the higgs, and he'll probably do it at a place like wisconsin
    in five years, i have never once had to purchase software: it's all linux/FOSS
what's the higgs?
why care?
how to find the higgs
    CERN
    LHC, acclerator, history?
        cost?
        # physicists
    detectors -> CMS, trigger, DAQ, sw trigger, T0 offline
        4 detectors, ATLAS CMS biggest collaborations
        redundant physics/check/compete

    FNAL T1, backup
        network connex to CERN, UW
        scale?
    UW T2, analysis, production
        network
        storage/dCache/HDFS/PhEDEx
        batch/Condor
        MC production (global map reduce)
    T3/T2 physicist
        fireworks/event display
        search for signal
stack
    OS: linux
    security: (gsi)ssh, kerberos, openssl/X509, libwrap
    services: AFS, apache, squid, mysql, postgres, redis, python, perl, java, tomcat
    grid/cluster: dCache, Condor, Globus

current:
    move computation to data
    copy stuff
    plan for failure
    small, 3 person team (operations/storage, grid/batch/dev, production)
    test/monitor

plans:
    dCache -> HDFS (larger community, better repliation and tools)
    glideins
    improve deployment
    devopsy

other:
    OSG?

photos
    hot aisle, mr2, mr1
    mdf
    office

how it all began
more info/links
    scientificlinux/centos/RH
educational resources
jobs
    spires
    UW OHR/physics
    UWM OHR/physics
-->

</article>

<script src="../sideshow/js/jquery-1.5.min.js"></script>
<script src="../sideshow/js/jquery-hashchange-1.3.min.js"></script>
<script src="../sideshow/js/sideshow.js"></script>
<script>
/* <![CDATA[ */
$("article").sideshow({help: false});
/* ]]> */
</script>
</body>
</html>

<!--
hi, my name is will maier and i work in the physics department at the university of wisconsin.
i'm here to talk about linux, but i'll have to cover a bit of physics first.
at this point, i should probably mention that i'm not a physicist myself; if you happen to be one, please feel free to step in at any point.

my group at the university is part of a large collaboration of scientists, engineers and computer folk around the world that are working on the largest science project ever.
we're trying to measure a subatomic particle that we're pretty sure exists, even though nobody has been able to observe one.
the particle is called the higgs boson; its existence was first proposed in 1964 (by peter higgs).
that year, several independent groups of physicists all arrived at a mechanism to explain why some elementary particles have mass and others don't.

since then, the higgs mechanism has become a key part of the standard model of particle physics, the set of theories that do a very good job of explaining experimental results.
we haven't yet observed the higgs boson itself, though, but we have some clues: we know roughly what it should look like, how much mass and energy it should have, and we know the conditions (high energy particle collisions) that should produce it.

lots of evidence gathered since then has made this mechanism

-->
